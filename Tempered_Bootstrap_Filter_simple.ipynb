{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\title{Problem Set 3}\n",
    "\n",
    "\\author{Pawel Langer - worked with Laszlo}\n",
    "\n",
    "\\date{November 2, 2017}\n",
    "\n",
    "\n",
    "\\maketitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\section*{State space representation}\n",
    "\n",
    "In order to solve the problem, we first stack all the equations into canonical the canonical form:\n",
    "\\begin{equation*}\n",
    "A(\\theta)X_{t}=B(\\theta)E_{t}X_{t+1}+C(\\theta)X_{t-1}+D(\\theta)\\eta_{t}\n",
    "\\end{equation*}\n",
    "With the matrices as follows:\n",
    "\\begin{equation*}\n",
    "A=\n",
    "\\begin{bmatrix}\n",
    "   1 & 0 & \\sigma & -1 & 0 \\\\\n",
    "  -\\kappa & 1 & 0 & 0 & -1 \\\\\n",
    "  -\\phi_{x}(1-\\rho_{i}) & -\\phi_{i}(1-\\rho_{i}) & 1 & 0 & 0 \\\\\n",
    "  0 & 0 & 0 & 1 & 0 \\\\\n",
    "  0 & 0 & 0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "B=\n",
    "\\begin{bmatrix}\n",
    "   1 & \\sigma & 0 & 0 & 0 \\\\\n",
    "   1 & \\beta & 0 & 0 & 0 \\\\\n",
    "   0 & 0 & 0 & 0 & 0 \\\\\n",
    "   0 & 0 & 0 & 0 & 0 \\\\\n",
    "   0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\n",
    ",C=\n",
    "\\begin{bmatrix}\n",
    "   0 & 0 & 0 & 0 & 0 \\\\\n",
    "   0 & 0 & 0 & 0 & 0 \\\\\n",
    "   0 & 0 & \\rho_{i} & 0 & 0 \\\\\n",
    "   0 & 0 & 0 & \\rho_{g} & 0 \\\\\n",
    "   0 & 0 & 0 & 0 & \\rho_{u} \\\\\n",
    "\\end{bmatrix}\n",
    ",D=\n",
    "\\begin{bmatrix}\n",
    "   0 & 0 & 0 \\\\\n",
    "   0 & 0 & 0 \\\\\n",
    "   \\sigma_{i} & 0 & 0 \\\\\n",
    "   0 & \\sigma_{g} & 0 \\\\\n",
    "    0 & 0 & \\sigma_{u} \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "Next we conjecture that the solution is linear:\n",
    "\\begin{equation*}\n",
    "X_{t}=FX_{t-1}+G\\eta_{t}\n",
    "\\end{equation*}\\\\\n",
    "Since we can solve for $G$ once we know $F$. The $F$ matrix solves the following quadratic equation:\n",
    "\\begin{equation*}\n",
    "BF^{2}-AF+C=0\n",
    "\\end{equation*}\\\\\n",
    "We solve for $F$ using the Generalized Schur Decomposition. The observed variables $Y_{t}$ evolve according to: \n",
    "\\begin{equation*}\n",
    "Y_{t}=H X_{t}+J \\zeta_{t}\n",
    "\\end{equation*}\\\\\n",
    "with \n",
    "\\begin{equation*}\n",
    "H=\n",
    "\\begin{bmatrix}\n",
    "   1 & 0 & 0 & 0 & 0 \\\\\n",
    "  0 & 1 & 0 & 0 & 0 \\\\\n",
    "  0 & 0 & 1 & 0 & 0 \\\\\n",
    " \\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "J= \\sigma_m\n",
    "\\begin{bmatrix}\n",
    "   1 & 0 & 0 \\\\\n",
    "  0 & 1 & 0  \\\\\n",
    "  0 & 0 & 1 \\\\\n",
    " \\end{bmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "import scipy.linalg as linalg\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import warnings; warnings.simplefilter('ignore')\n",
    "from tqdm import tqdm\n",
    "import quandl as Quandl\n",
    "import time\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True parameter vector is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_true = np.array([2.09,0.98,2.25,0.65,0.81,0.98,0.93,0.34,3.16,0.51,0.19,0.65,0.24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corresponding to the parameters:\n",
    "\\begin{equation}\n",
    "\\tau, \\kappa,\\beta, \\phi_{\\pi} , \\phi_{x}, \\rho_i, \\rho_g, \\rho_z,r^{A},\\pi^{Q},\\gamma^{Q}, \\sigma_i,\\sigma_g,\\sigma_z\n",
    "\\end{equation}\n",
    "and the standard deviation $\\sigma_m$ for the observations is set initially to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_guess = np.array([3.26,0.89,1.88,0.53,0.76,0.98,0.89,0.19,3.29,0.73,0.20,0.58,0.29])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving for the matrices and loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Kalman filter for Tempered Particle Filter\n",
    "no_st = 6\n",
    "no_observables = 3\n",
    "@jit\n",
    "def eval_theta(param):\n",
    "    tau, kappa, psi_pi,psi_y,rho_i,rho_g,rho_z,const_r, const_i,const_y, sigma_i,sigma_g,sigma_z = param\n",
    "    beta = 1/(1+const_r/400) \n",
    "    #beta = 1\n",
    "    no_st = 6 #Number of x states - underlying states\n",
    "    no_observables = 3\n",
    "    #The X_t matrix\n",
    "    A = np.reshape([1,0,1/tau,-1,0,0,\n",
    "                    -kappa,1,0,kappa,0,0,\n",
    "                    -psi_y*(1 - rho_i), - psi_pi * (1-rho_i),1,(1-rho_i)*psi_y,0,0,\n",
    "                   0,0,0,1,0,0,\n",
    "                    0,0,0,0,1,0,\n",
    "                   0,0,0,0,0,1],(no_st,no_st))\n",
    "    #The X_t+1 matrix\n",
    "    B = np.reshape([1, 1/tau, 0, -1, 1/tau,0,\n",
    "                  0, beta, 0, 0, 0,0,\n",
    "                  0, 0, 0, 0, 0,0,\n",
    "                  0, 0, 0, 0, 0,0,\n",
    "                  0, 0, 0, 0, 0,0,\n",
    "                   0, 0, 0, 0, 0,0],(no_st,no_st))\n",
    "    #The X_t-1 matrix\n",
    "    C = np.reshape([0, 0, 0, 0, 0,0,\n",
    "                    0, 0, 0, 0, 0,0,\n",
    "                    0, 0, rho_i, 0, 0,0,\n",
    "                    0, 0, 0, rho_g, 0,0,\n",
    "                    0, 0, 0, 0, rho_z,0,\n",
    "                   1, 0, 0, 0, 0,0],(no_st,no_st))\n",
    "    #The error matrix eta\n",
    "    D = np.reshape([0, 0, 0,\n",
    "                    0, 0, 0,\n",
    "                   sigma_i, 0, 0,\n",
    "                    0, sigma_g, 0,\n",
    "                    0, 0, sigma_z,\n",
    "                   0, 0, 0,],(no_st,no_observables))\n",
    "    H = np.zeros((no_observables,no_st))\n",
    "    H[0,0] = 1\n",
    "    H[0,4] = 1\n",
    "    H[0,5] = -1\n",
    "    H[1,1] = 4\n",
    "    H[2,2] = 4\n",
    "    #J = np.eye(no_observables,no_observables)\n",
    "    Const_obs = np.zeros((no_observables,1))\n",
    "    Const_obs[0,0] = const_y\n",
    "    Const_obs[1,0] = const_i\n",
    "    Const_obs[2,0] = 4*const_y + const_i + const_r\n",
    "    K = np.bmat([[np.zeros((no_st,no_st)), np.eye(no_st)], [-C, A]])\n",
    "    L = np.bmat([[ np.eye(no_st),np.zeros((no_st,no_st))], [np.zeros((no_st,no_st)), B]])\n",
    "    T,S,alppha,betta,Q,Z = linalg.ordqz(K,L,sort='iuc')\n",
    "    Z = Z.T\n",
    "    #print(1)\n",
    "    #F = Z[(no_st):(2*no_st),0:no_st] @ linalg.inv(Z[0:no_st,0:no_st])\n",
    "    if (linalg.det(Z[0:no_st,0:no_st]) != 0):\n",
    "        F = (linalg.solve(Z[0:no_st,0:no_st],Z[0:no_st,(no_st):(2*no_st)])).T\n",
    "        #print(2)\n",
    "        #G = np.linalg.inv(A - (B @ F)) @ D\n",
    "        if(linalg.det(A - (B @ F)) != 0):\n",
    "            G = linalg.solve(A - (B @ F),D)\n",
    "        else:\n",
    "            F = np.eye(no_st)\n",
    "            G = F\n",
    "    else:\n",
    "        F = np.eye(no_st)\n",
    "        G = F   \n",
    "    J =np.eye(no_observables,no_observables)\n",
    "    J[0,0] = 0.1160\n",
    "    J[1,1] = 0.2942\n",
    "    J[2,2] = 0.4476\n",
    "    #return A\n",
    "    err = B @ F @ F - A @ F + C \n",
    "    return F , G , H, J,Const_obs,err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def KF_filter(F,G,H,J,x_obs,Const_obs):\n",
    "    T = x_obs.shape[0]\n",
    "    no_state = F.shape[0]\n",
    "    no_measurement = J.shape[0]\n",
    "    X = np.zeros((no_state,1))  # Number of state variables\n",
    "    #P = np.mean(J.diagonal()) * np.zeros((no_state,no_state))  #Initial variance guess\n",
    "    P = linalg.solve_discrete_lyapunov(F,G @ G.T)\n",
    "    lnp = 0\n",
    "    G_quad = G @ G.T\n",
    "    J_quad = (J @ J.T)\n",
    "    I_d = np.eye(no_measurement,no_measurement)\n",
    "    for t in range(x_obs.shape[0]):\n",
    "        X = F @ X\n",
    "        P = F @ P @ F.T + G_quad\n",
    "        y = x_obs[t,None].T - H @ X - Const_obs\n",
    "        H_P_multi = H @ P\n",
    "        V = H_P_multi @ H.T + J_quad\n",
    "        inv_V = linalg.cho_solve(linalg.cho_factor(V,lower=True),I_d )\n",
    "        #print(linalg.det(P))\n",
    "        lnp = lnp - 0.5 * (np.log(np.linalg.det(V)) + y.T @ inv_V @ y)\n",
    "        X = X + P @ H.T @ inv_V @ y\n",
    "        P = P - H_P_multi.T @ inv_V @ H_P_multi\n",
    "    return lnp - 0.5 * T * no_measurement *  np.log(2*np.pi)  #With 2pi adjustment constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_likelihood(param,x_obs):\n",
    "    F,G,H,J = eval_theta(param)\n",
    "    eig_val,eig_vec = linalg.eig(F)\n",
    "    if (np.all(np.absolute(eig_val) >=1)) ==0:\n",
    "        res = KF_filter(F,G,H,J,x_obs)\n",
    "    else:\n",
    "        res = -np.inf\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GDPt = Quandl.get(\"FRED/GDPC1\",authtoken=\"5QphWABG_zpJsB5dy4yW\",start_date=\"1983-04-01\", end_date=\"2003-01-01\")\n",
    "GDPt1 = Quandl.get(\"FRED/GDPC1\",authtoken=\"5QphWABG_zpJsB5dy4yW\",start_date=\"1983-01-01\", end_date=\"2002-10-01\")\n",
    "POPt = Quandl.get(\"FRED/CNP16OV\", collapse=\"quarterly\",authtoken=\"5QphWABG_zpJsB5dy4yW\",start_date=\"1983-01-01\", end_date=\"2002-10-01\")\n",
    "POPt1 = Quandl.get(\"FRED/CNP16OV\", collapse=\"quarterly\",authtoken=\"5QphWABG_zpJsB5dy4yW\",start_date=\"1982-10-31\", end_date=\"2002-07-31\")\n",
    "FFR = Quandl.get(\"FRED/FEDFUNDS\", collapse=\"quarterly\",authtoken=\"5QphWABG_zpJsB5dy4yW\",start_date=\"1983-01-01\", end_date=\"2002-10-01\")\n",
    "CPIt = Quandl.get(\"FRED/CPIAUCSL\", collapse=\"quarterly\",authtoken=\"5QphWABG_zpJsB5dy4yW\",start_date=\"1983-01-01\", end_date=\"2002-10-01\")\n",
    "CPIt1 = Quandl.get(\"FRED/CPIAUCSL\", collapse=\"quarterly\",authtoken=\"5QphWABG_zpJsB5dy4yW\",start_date=\"1982-10-31\", end_date=\"2002-07-31\")\n",
    "T = 80\n",
    "x_obs = np.zeros((T,no_observables))\n",
    "x_obs[:,0] = 100*(np.log(GDPt.values/POPt.values)-np.log(GDPt1.values/POPt1.values)).flatten()\n",
    "x_obs[:,1] = 400*(np.log(CPIt.values/CPIt1.values)).flatten()\n",
    "x_obs[:,2] = FFR.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GDPt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-d3c677927c2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mno_observables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_obs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGDPt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mPOPt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGDPt1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mPOPt1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx_obs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCPIt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mCPIt1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_obs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFFR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GDPt' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_obs = np.loadtxt(\"DataRecession.txt\", delimiter=\",\")\n",
    "#x_obs = np.loadtxt(\"DataFREDcorrect.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\section*{Simulation}\n",
    "Now we similate for 200 periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F,G,H,J,Const_obs,err = eval_theta(param_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-246.67813913]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trueval = KF_filter(F,G,H,J, x_obs,Const_obs)\n",
    "Trueval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_sample(mean,var,no_sample):\n",
    "    return np.random.multivariate_normal(mean,var,no_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Notes at: https://www.dropbox.com/home/Econometrics%20Notes?preview=nyu_Bayes5_2017.pdf\n",
    "def particle_filter(F,G,H,J,x_obs,Const_obs,no_simu = 10000):  #F,G,H,J matrix from Kalman filter computation\n",
    "    T = x_obs.shape[0]\n",
    "    no_state = F.shape[0]\n",
    "    no_measurement = J.shape[0]\n",
    "    X_mean = np.zeros((no_st,1)) #Initialize the particle cloud at 0\n",
    "    V_x = linalg.solve_discrete_lyapunov(F,G @ G.T) #Initial Variance function solved from FVF'−F+G @ G.T=0\n",
    "    P = V_x #+ 10 * np.eye(no_state,no_state) # P matrix is the initial variance\n",
    "    lnp = 0 # Initialize likelihood value\n",
    "    #Eta = np.reshape(random_sample(np.zeros(no_state), G @ G.T,no_simu*T),(T,no_simu,no_state),order='F') \n",
    "    Eta = np.reshape(np.random.multivariate_normal(np.zeros(no_state), G @ G.T,no_simu*T),(T,no_simu,no_state),order='F') \n",
    "    #Eta shock reshaped for the number similutaion and time periods, ordered by Fortran optimal code\n",
    "    X = np.random.multivariate_normal(X_mean.flatten(),P,no_simu) #Initial X draw\n",
    "    p_yx = np.zeros((X.shape[0]))\n",
    "    Var_y = J @ J.T\n",
    "    inv_Var_y = linalg.inv(Var_y)\n",
    "    const_obs = np.tile(Const_obs.T,(no_simu,1))\n",
    "    for t in range(T): #Loop over time periods and add up the likelihood\n",
    "        X_next = X @ F.T + Eta[t,:,:]             #Propagate the paricle forward\n",
    "        y_dev = x_obs[t,:] -X_next @ H.T - const_obs\n",
    "        p_yx = np.exp( -0.5 * (np.log(np.linalg.det(Var_y)) + np.diag(( y_dev) @ inv_Var_y @ (y_dev).T))) \n",
    "        #Computing the likelihoood\n",
    "        p_yy = p_yx.mean()\n",
    "        lnp = np.log(p_yy) + lnp\n",
    "        weights_val = p_yx/p_yy/no_simu #Giving weights to the observations\n",
    "        multisample = np.random.multinomial(no_simu, weights_val.flatten(), size=1).flatten() #resampling based on weights\n",
    "        X_next = np.repeat(X_next,multisample,axis = 0) #Creating a new sample based on the weights\n",
    "        X = X_next.copy()\n",
    "    return lnp - 0.5 * T * no_measurement *  np.log(2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-710.11717537370441"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particle_filter(F,G,H,J,x_obs,Const_obs,no_simu = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_runs = 20\n",
    "likelihood_val = np.zeros((no_runs,2))\n",
    "for i in tqdm(range(no_runs)):\n",
    "    t0 = time.time()\n",
    "    likelihood_val[i,0] = particle_filter(F,G,H,J,x_obs,Const_obs,no_simu = 40000)\n",
    "    t1 = time.time()\n",
    "    likelihood_val[i,1] = t1-t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-465.64124294 34.9371181946 371.083233714\n"
     ]
    }
   ],
   "source": [
    "Bias = np.mean(likelihood_val[:,0])\n",
    "StDev = np.std(likelihood_val[:,0])\n",
    "AvgTime = np.mean(likelihood_val[:,1])\n",
    "print(Bias, StDev,AvgTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-246.67813913]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trueval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tempered_particle_filter(F,G,H,J,x_obs,Const_obs,no_simu,r_star = 2,phi_init = 0.2,markov_time = 1):  #F,G,H,J matrix from Kalman filter computation\n",
    "    #mvn = multivariate_normal(0,) #create a multivariate Gaussian object with specified mean and covariance matrix\n",
    "    #p = mvn.pdf(x) #evaluate the probability density at x\n",
    "    T = x_obs.shape[0]\n",
    "    no_state = F.shape[0]\n",
    "    no_measurement = J.shape[0]\n",
    "    X_mean = np.zeros((no_st,1)) #Initialize the particle cloud at 0\n",
    "    V_x = linalg.solve_discrete_lyapunov(F,G @ G.T) #Initial Variance function solved from FVF'−F+G @ G.T=0\n",
    "    P = V_x# + 10 * np.eye(5,5) # P matrix is the initial variance\n",
    "    lnp = 0 # Initialize likelihood value\n",
    "    Eta = np.reshape(np.random.multivariate_normal(np.zeros(no_measurement), np.eye(no_measurement),no_simu*T),(T,no_simu,no_measurement),order='F') \n",
    "    #Eta shock reshaped for the number similutaion and time periods, ordered by Fortran optimal code\n",
    "    #Eta = np.reshape(np.random.multivariate_normal(np.zeros(no_state), G @ G.T,no_simu*T),(T,no_simu,no_state),order='F') \n",
    "    X =  np.random.multivariate_normal(X_mean.flatten(),np.eye(no_state),no_simu) @ linalg.cholesky(P).T\n",
    "    #X = random_sample(X_mean.flatten(),P,no_simu) #Initial X draw\n",
    "    p_yx = np.zeros((X.shape[0]))\n",
    "    const_obs = Const_obs.T\n",
    "    Var_y = J @ J.T\n",
    "    Var_eps = G @ G.T \n",
    "    inv_Var_y = linalg.inv(Var_y)\n",
    "    maxiter = 30 # max number of iterations in the while loop\n",
    "    accept_shock = np.random.uniform(size = (markov_time,no_simu,T,maxiter))\n",
    "    #mutate_shock = np.reshape(np.random.multivariate_normal(np.zeros(no_state),np.eye(no_state),no_simu*T*maxiter*markov_time),(T,no_simu,no_state,maxiter,markov_time),order='F')\n",
    "    mutate_shock = np.reshape(np.random.multivariate_normal(np.zeros(no_measurement),np.eye(no_measurement),no_simu*T*maxiter*markov_time\n",
    "                                           ),(T,no_simu,no_measurement,maxiter,markov_time),order='F')\n",
    "    def eval_weights(phi,phi_prev,e_dev):\n",
    "        return np.exp(-e_dev*(phi-phi_prev))*(phi/phi_prev)**(no_measurement/2)\n",
    "    def eval_inef_ratio(phi,phi_prev,e_dev,r_star):\n",
    "        eval_weights_tmp = eval_weights(phi,phi_prev,e_dev)\n",
    "        return np.sum((eval_weights_tmp/eval_weights_tmp.mean())**2)/no_simu -r_star\n",
    "        #print(np.mean(np.exp(-2*(phi-phi_prev) * e_dev))/(np.mean(np.exp(-(phi-phi_prev) * e_dev)))**2 - r_star)\n",
    "        #return np.mean(np.exp(-2*(phi-phi_prev) * e_dev))/(np.mean(np.exp(-(phi-phi_prev) * e_dev)))**2 - r_star\n",
    "    def eval_inef_ratio_init(phi,r_star,no_simu,e_dev):\n",
    "        A1=(2 * np.pi)**(-no_measurement/2) *  np.exp(- phi* e_dev) * (np.linalg.det(inv_Var_y*phi))**(1/2)\n",
    "        B1=A1.mean()\n",
    "        return np.sum((A1/B1)**2)/no_simu - r_star\n",
    "    def eval_weights_avg(eval_weights_tmp):\n",
    "        return eval_weights_tmp/ np.mean(eval_weights_tmp)/no_simu\n",
    "    def c_var_updater_mh(x):\n",
    "        return 0.95 + 0.1 * np.exp(20 * (x-0.4))/(1 + np.exp(20 * (x-0.4)))\n",
    "    \n",
    "    for t in range(T): #Loop over time periods and add up the likelihood\n",
    "        print(t)\n",
    "        #const_obs = 0\n",
    "        c_var = 0.3\n",
    "        #phi_tmp1 = phi_init\n",
    "        #phi_tmp2 = phi_init\n",
    "        X_ft = X @ F.T\n",
    "        X_next = X_ft + Eta[t,:,:] @ G.T           #Propagate the paricle forward\n",
    "        #plt.hist(Eta[t,:,:])\n",
    "        y_dev = x_obs[t,:] -X_next @ H.T - const_obs\n",
    "        e_dev = 0.5 * np.diag(( y_dev) @ inv_Var_y @ (y_dev).T)\n",
    "        phi_init1 = optimize.bisect(eval_inef_ratio_init,phi_init,1,args = (r_star,no_simu,e_dev))\n",
    "        phi = phi_init1\n",
    "        #print(phi)\n",
    "        p_yx = np.exp(- phi* e_dev) * (np.linalg.det(inv_Var_y*phi))**(1/2)\n",
    "        ##p_yx_true = np.exp( -0.5 * np.log(np.linalg.det(Var_y)) - e_dev) \n",
    "        #Computing the likelihoood\n",
    "        p_yy = p_yx.mean()\n",
    "        weights_val = p_yx/p_yy/no_simu #Giving weights to the observations\n",
    "        multisample = np.random.multinomial(no_simu, weights_val.flatten(), size=1).flatten() #resampling based on weights\n",
    "        X_next = np.repeat(X_next,multisample,axis = 0) \n",
    "        X = np.repeat(X,multisample,axis = 0)#Creating a new sample based on the weights\n",
    "        Eta_mutate = np.repeat(Eta[t,:,:] ,multisample,axis = 0)#Creating a new sample based on the weights\n",
    "        #X = X_next_sample.copy()\n",
    "        iterate = 0\n",
    "        lnp = np.log(p_yx.mean()) + lnp - 0.5 * no_measurement *  np.log(2*np.pi)\n",
    "        #print(np.log(p_yx.mean()))\n",
    "        while (phi <1):\n",
    "        #while (iterate < 0):\n",
    "            #print(iterate,phi,lnp)\n",
    "            #print(phi,phi_tmp1,phi_tmp2)\n",
    "            y_dev = x_obs[t,:] -X_next @ H.T - const_obs\n",
    "            e_dev = 0.5 * np.diag(( y_dev) @ inv_Var_y @ (y_dev).T)\n",
    "            if(eval_inef_ratio(1,phi,e_dev,r_star) <= 0):\n",
    "                weights_lik = eval_weights(1,phi,e_dev)\n",
    "                #phi_prev = phi\n",
    "                phi = 1\n",
    "            else:\n",
    "                #phi_tmp = optimize.fsolve(eval_inef_ratio,0.5,args = (phi,e_dev,r_star))\n",
    "                #phi_tmp = optimize.root(eval_inef_ratio,(phi +1)/6,args = (phi,e_dev,r_star))\n",
    "                #phi_tmp = optimize.brentq(eval_inef_ratio,phi,1,args = (phi,e_dev,r_star))\n",
    "                phi_tmp = optimize.bisect(eval_inef_ratio,phi,1,args = (phi,e_dev,r_star))\n",
    "                #print(lnp,phi,phi_tmp)\n",
    "                #weights_lik = eval_weights(phi_tmp.x,phi,e_dev)\n",
    "                weights_lik = eval_weights(phi_tmp,phi,e_dev)\n",
    "                #print(weights_lik)\n",
    "                phi = phi_tmp \n",
    "                #phi = phi_tmp.x\n",
    "            weights_val = eval_weights_avg(weights_lik)\n",
    "            #print(weights_val.max())\n",
    "            multisample = np.random.multinomial(no_simu, weights_val.flatten(), size=1).flatten() #resampling based on weights\n",
    "            X_next = np.repeat(X_next,multisample,axis = 0) \n",
    "            X = np.repeat(X,multisample,axis = 0)#Creating a new sample based on the weights\n",
    "            Eta_mutate = np.repeat(Eta_mutate ,multisample,axis = 0)#Creating a new sample based on the weights\n",
    "            \n",
    "            for mt in range(markov_time):\n",
    "                #print('runnnn')\n",
    "                X_ft = X @ F.T\n",
    "                Eta_mutate_tmp = Eta_mutate + c_var * mutate_shock[t,:,:,iterate,mt]\n",
    "                X_next_mt_sample = X_ft + Eta_mutate_tmp @ G.T          #Propagate the paricle forward\n",
    "                y_dev_mt_sample = x_obs[t,:] -X_next_mt_sample @ H.T - const_obs\n",
    "                e_dev_mt_sample = 0.5 * np.diag(( y_dev_mt_sample) @ ( inv_Var_y) @ (y_dev_mt_sample).T)\n",
    "                p_yx_tmp =  - phi* e_dev_mt_sample\n",
    "                #X_next_mt_past = X_ft + Eta_mutate             #Propagate the paricle forward\n",
    "                y_dev_mt_past = x_obs[t,:] -X_next @ H.T - const_obs\n",
    "                e_dev_mt_past = 0.5 * np.diag(( y_dev_mt_past) @ (  inv_Var_y) @ (y_dev_mt_past).T)\n",
    "                p_yx_past =  -  phi* e_dev_mt_past\n",
    "                pr_ratio = -0.5 * np.sum(Eta_mutate_tmp**2 -Eta_mutate**2,1)\n",
    "                acceptance_rate = np.exp( p_yx_tmp - p_yx_past+pr_ratio)\n",
    "                decision = acceptance_rate > accept_shock[mt,:,t,iterate]\n",
    "                tiled_decision = np.tile(decision,(no_measurement,1)).T\n",
    "                tiled_decision_x = np.tile(decision,(no_state,1)).T\n",
    "                #print(tiled_decision.shape)\n",
    "                Eta_mutate = Eta_mutate_tmp * tiled_decision + (1 - tiled_decision) * Eta_mutate\n",
    "                X_next = X_next_mt_sample * tiled_decision_x + (1 - tiled_decision_x) * X_next\n",
    "                #print(decision.sum()/no_simu)\n",
    "            c_var = c_var * c_var_updater_mh(decision.sum()/no_simu)\n",
    "            #X_next = X_ft + Eta_mutate\n",
    "            iterate = iterate +1\n",
    "            lnp = np.log(np.mean(weights_lik))  + lnp\n",
    "            #print(np.log(np.mean(weights_lik)))\n",
    "            #lnp = np.log(np.sum(weights_val))  + lnp\n",
    "            #print(lnp)\n",
    "        X = X_next.copy()\n",
    "    return lnp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-262.65775503342263"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempered_particle_filter(F,G,H,J,x_obs,Const_obs,5500,r_star = 2,phi_init = 0.00001,markov_time = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-265.6514201112559"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempered_particle_filter(F,G,H,J,x_obs,Const_obs,5500,r_star = 2,phi_init = 0.0002,markov_time = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 74.31629013+0.j,  11.55352912+0.j,   4.99137092+0.j]),\n",
       " array([[ 1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  0.,  1.]]))"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linalg.eig(linalg.inv(J @ J.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                        | 1/20 [02:24<45:43, 144.40s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-56df5aaa5935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_runs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mlikelihood_val1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempered_particle_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_obs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mConst_obs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr_star\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mphi_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.002\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarkov_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-117-c22980ccb9cc>\u001b[0m in \u001b[0;36mtempered_particle_filter\u001b[1;34m(F, G, H, J, x_obs, Const_obs, no_simu, r_star, phi_init, markov_time)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mmaxiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m \u001b[1;31m# max number of iterations in the while loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0maccept_shock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmarkov_time\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mno_simu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mmutate_shock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mno_simu\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmarkov_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mno_simu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mno_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmarkov_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mphi_prev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0me_dev\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mphi_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mphi_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_measurement\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    230\u001b[0m            [5, 6]])\n\u001b[0;32m    231\u001b[0m     \"\"\"\n\u001b[1;32m--> 232\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "no_runs = 20\n",
    "likelihood_val1 = np.zeros((no_runs,2))\n",
    "for i in tqdm(range(no_runs)):\n",
    "    t0 = time.time()\n",
    "    likelihood_val1[i,0] = tempered_particle_filter(F,G,H,J,x_obs,Const_obs,7000,r_star = 2,phi_init = 0.002,markov_time = 1)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    likelihood_val1[i,1] = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.829112415 0.952899583544 278.806489515\n"
     ]
    }
   ],
   "source": [
    "Bias1 = np.mean(likelihood_val1[0:15,0])+306.5\n",
    "StDev1 = np.std(likelihood_val1[0:15,0])\n",
    "AvgTime1 = np.mean(likelihood_val1[0:15,1])\n",
    "print(Bias1, StDev1,AvgTime1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-321.79358071,  260.21936464],\n",
       "       [-321.52966305,  257.07757258],\n",
       "       [-319.74966799,  274.76480484],\n",
       "       [-321.03674369,  270.34807229],\n",
       "       [-318.77617059,  262.83290386],\n",
       "       [-320.87006459,  244.65884948],\n",
       "       [-320.95592647,  275.9442749 ],\n",
       "       [-319.94505529,  288.21007514],\n",
       "       [-319.71781955,  290.96917367],\n",
       "       [-320.8293161 ,  294.37778306],\n",
       "       [-320.26597819,  292.70448208],\n",
       "       [-320.87039466,  294.1811583 ],\n",
       "       [-318.10857379,  294.24260688],\n",
       "       [-320.03536756,  291.18447828],\n",
       "       [-320.45236399,  290.38174272],\n",
       "       [-321.21540119,  292.31930947],\n",
       "       [-321.97603628,  289.67436266],\n",
       "       [-317.08295173,  290.12486768],\n",
       "       [-319.08324511,  292.5842042 ],\n",
       "       [-319.96450079,  287.21079969]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_val1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Section on class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_true = np.array([1,0.2,0.99,1.25,0.25,0.5,0.75,0.75,1,1,2])\n",
    "sigma_m = 0.1\n",
    "no_st = 5\n",
    "no_observables = 3\n",
    "def eval_theta(param,sigma_m):\n",
    "    sigma, kappa, beta , phi_pi,phi_x,rho_i,rho_g,rho_u,sigma_g,sigma_u,sigma_i = param\n",
    "    no_st = 5 #Number of x states - underlying states\n",
    "    #The X_t matrix\n",
    "    A = np.reshape([1,0,sigma,-1,0,\n",
    "                    -kappa,1,0,0,-1,\n",
    "                    -phi_x*(1 - rho_i), - phi_pi * (1-rho_i),1,0,0,\n",
    "                   0,0,0,1,0,\n",
    "                    0,0,0,0,1],(no_st,no_st))\n",
    "    #The X_t+1 matrix\n",
    "    B = np.reshape([1, sigma, 0, 0, 0,\n",
    "                  0, beta, 0, 0, 0,\n",
    "                  0, 0, 0, 0, 0,\n",
    "                  0, 0, 0, 0, 0,\n",
    "                  0, 0, 0, 0, 0],(no_st,no_st))\n",
    "    #The X_t-1 matrix\n",
    "    C = np.reshape([0, 0, 0, 0, 0,\n",
    "                    0, 0, 0, 0, 0,\n",
    "                    0, 0, rho_i, 0, 0,\n",
    "                    0, 0, 0, rho_g, 0,\n",
    "                    0, 0, 0, 0, rho_u],(no_st,no_st))\n",
    "    #The error matrix eta\n",
    "    D = np.reshape([0, 0, 0,\n",
    "                    0, 0, 0,\n",
    "                    sigma_i, 0, 0,\n",
    "                    0, sigma_g, 0,\n",
    "                    0, 0, sigma_u],(no_st,3))\n",
    "    K = np.bmat([[np.zeros((no_st,no_st)), np.eye(no_st)], [-C, A]])\n",
    "    L = np.bmat([[ np.eye(no_st),np.zeros((no_st,no_st))], [np.zeros((no_st,no_st)), B]])\n",
    "    T,S,alppha,betta,Q,Z = linalg.ordqz(K,L,sort='iuc')\n",
    "    Z = Z.T\n",
    "    #print(1)\n",
    "    #F = Z[(no_st):(2*no_st),0:no_st] @ linalg.inv(Z[0:no_st,0:no_st])\n",
    "    if (linalg.det(Z[0:no_st,0:no_st]) != 0):\n",
    "        F = (linalg.solve(Z[0:no_st,0:no_st],Z[0:no_st,(no_st):(2*no_st)])).T\n",
    "        #print(2)\n",
    "        #G = np.linalg.inv(A - (B @ F)) @ D\n",
    "        if(linalg.det(A - (B @ F)) != 0):\n",
    "            G = linalg.solve(A - (B @ F),D)\n",
    "        else:\n",
    "            F = np.eye(no_st)\n",
    "            G = F\n",
    "    else:\n",
    "        F = np.eye(no_st)\n",
    "        G = F   \n",
    "    H = np.eye(3,5) \n",
    "    J = sigma_m*np.eye(3,3)\n",
    "    return F , G , H, J\n",
    "def KF_filter(F,G,H,J,x_obs):\n",
    "    X = np.zeros((5,1))  # Number of state variables\n",
    "    P = sigma_m * np.eye(5,5)  #Initial variance guess\n",
    "    lnp = 0\n",
    "    G_quad = G @ G.T\n",
    "    J_quad = J @ J.T\n",
    "    I_d = np.eye(3,3)\n",
    "    for t in range(x_obs.shape[0]):\n",
    "        X = F @ X\n",
    "        P = F @ P @ F.T + G_quad\n",
    "        y = H @ X\n",
    "        H_P_multi = H @ P\n",
    "        V = H_P_multi @ H.T + J_quad\n",
    "        inv_V = linalg.cho_solve(linalg.cho_factor(V,lower=True),I_d )\n",
    "        x_obs_t_T = x_obs[t,None].T\n",
    "        lnp = lnp - 0.5 * (np.log(np.linalg.det(V)) + (x_obs_t_T - y).T @ inv_V @ \n",
    "                           (x_obs_t_T-y))\n",
    "        X = X + P @ H.T @ inv_V @ (x_obs_t_T - y)\n",
    "        P = P - H_P_multi.T @ inv_V @ H_P_multi\n",
    "    return lnp- 0.5 * x_obs.shape[0] * x_obs.shape[1] *  np.log(2*np.pi)  #With 2pi adjustment constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 200\n",
    "x = np.zeros((5,T)) \n",
    "v = np.random.randn(3,T)\n",
    "F , G, H, J = eval_theta(param_true, sigma_m)\n",
    "for t in range(T-1):\n",
    "    x[:,t + 1] = F @ x[:,t] + G @ v[:,t + 1]\n",
    "x_obs = np.zeros((T,3))\n",
    "for t in range(T):\n",
    "    x_obs[t,:] = H @ x[:,t] + J @ v[:,t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1287.57807344]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KF_filter(F,G,H,J,x_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2  0.  -0. ]\n",
      " [ 0.   0.2 -0. ]\n",
      " [ 0.   0.   0.2]]\n"
     ]
    }
   ],
   "source": [
    "Var_y1 = J @ J.T\n",
    "inv_Var_y1 = linalg.inv(Var_y1)\n",
    "print(inv_Var_y1*0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2223.73084338 23.71008062362671\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "Result1=particle_filter(F,G,H,J,x_obs,np.zeros((no_observables,1)),no_simu = 5000)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(Result1, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1589.68208288 242.73200821876526\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "Result1=tempered_particle_filter(F,G,H,J,x_obs,np.zeros((no_observables,1)),no_simu = 4000,r_star = 2,phi_init = 0.02,markov_time = 1)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(Result1, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1517.44462027 1771.5278310775757\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "Result1=tempered_particle_filter(F,G,H,J,x_obs,np.zeros((no_observables,1)),no_simu = 11000,r_star = 2,phi_init = 0.02,markov_time = 1)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(Result1, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tempered_particle_filter(F,G,H,J,x_obs,Const_obs,no_simu,r_star = 2,phi_init = 0.2,markov_time = 1):  #F,G,H,J matrix from Kalman filter computation\n",
    "    T = x_obs.shape[0]\n",
    "    no_state = F.shape[0]\n",
    "    no_measurement = J.shape[0]\n",
    "    X_mean = np.zeros((no_st,1)) #Initialize the particle cloud at 0\n",
    "    V_x = linalg.solve_discrete_lyapunov(F,G @ G.T) #Initial Variance function solved from FVF'−F+G @ G.T=0\n",
    "    P = V_x# + 10 * np.eye(5,5) # P matrix is the initial variance\n",
    "    lnp = 0 # Initialize likelihood value\n",
    "    Eta = np.reshape(random_sample(np.zeros(no_state), G @ G.T,no_simu*T),(T,no_simu,no_state),order='F') \n",
    "    #Eta shock reshaped for the number similutaion and time periods, ordered by Fortran optimal code\n",
    "    X = random_sample(X_mean.flatten(),P,no_simu) #Initial X draw\n",
    "    p_yx = np.zeros((X.shape[0]))\n",
    "    const_obs = np.tile(Const_obs.T,(no_simu,1))\n",
    "    Var_y = J @ J.T\n",
    "    Var_eps = G @ G.T \n",
    "    inv_Var_y = linalg.inv(Var_y)\n",
    "    pinv_var_eps = linalg.pinv(Var_eps)\n",
    "    maxiter = 20 # max number of iterations in the while loop\n",
    "    accept_shock = np.random.uniform(size = (markov_time,no_simu,T,maxiter))\n",
    "    mutate_shock = np.reshape(random_sample(np.zeros(no_state),np.eye(no_state),no_simu*T*maxiter*markov_time),(T,no_simu,no_state,maxiter,markov_time),order='F')\n",
    "    def eval_weights(phi,phi_prev,e_dev):\n",
    "        return (phi/phi_prev)**(no_measurement/2) * np.exp(-e_dev*(phi-phi_prev))\n",
    "    def eval_inef_ratio(phi,phi_prev,e_dev,r_star):\n",
    "        return np.mean(np.exp(-2*(phi-phi_prev) * e_dev))/(np.mean(np.exp(-(phi-phi_prev) * e_dev)))**2 - r_star\n",
    "    def eval_weights_avg(eval_weights_tmp):\n",
    "        return eval_weights_tmp/ np.mean(eval_weights_tmp)/no_simu\n",
    "    def c_var_updater_mh(x):\n",
    "        return 0.95 + 0.1 * np.exp(20 * (x-0.4))/(1 + np.exp(20 * (x-0.4)))\n",
    "    \n",
    "    for t in range(T): #Loop over time periods and add up the likelihood\n",
    "        c_var = 0.3\n",
    "        phi = phi_init\n",
    "        #phi_tmp1 = phi_init\n",
    "        #phi_tmp2 = phi_init\n",
    "        X_ft = X @ F.T\n",
    "        X_next = X_ft + Eta[t,:,:]             #Propagate the paricle forward\n",
    "        y_dev = x_obs[t,:] -X_next @ H.T - const_obs\n",
    "        e_dev = 0.5 * np.diag(( y_dev) @ inv_Var_y @ (y_dev).T)\n",
    "        p_yx = np.exp(- phi* e_dev) * (np.linalg.det(inv_Var_y*phi))**(1/2)\n",
    "        ##p_yx_true = np.exp( -0.5 * np.log(np.linalg.det(Var_y)) - e_dev) \n",
    "        #Computing the likelihoood\n",
    "        p_yy = p_yx.mean()\n",
    "        weights_val = p_yx/p_yy/no_simu #Giving weights to the observations\n",
    "        multisample = np.random.multinomial(no_simu, weights_val.flatten(), size=1).flatten() #resampling based on weights\n",
    "        X_next = np.repeat(X_next,multisample,axis = 0) #Creating a new sample based on the weights\n",
    "        #X = X_next_sample.copy()\n",
    "        iterate = 0\n",
    "        lnp = np.log(p_yx.mean()) + lnp\n",
    "        while (phi <1):\n",
    "        #while (iterate < 0):\n",
    "            #print(phi,phi_tmp1,phi_tmp2)\n",
    "            y_dev = x_obs[t,:] -X_next @ H.T - const_obs\n",
    "            e_dev = 0.5 * np.diag(( y_dev) @ inv_Var_y @ (y_dev).T)\n",
    "            if(eval_inef_ratio(1,phi,e_dev,r_star) <= 0):\n",
    "                weights_lik = eval_weights(1,phi,e_dev)\n",
    "                #phi_prev = phi\n",
    "                phi = 1\n",
    "            else:\n",
    "                #phi_tmp = optimize.fsolve(eval_inef_ratio,0.5,args = (phi,e_dev,r_star))\n",
    "                phi_tmp = optimize.root(eval_inef_ratio,(phi +1)/2,args = (phi,e_dev,r_star))\n",
    "                #phi_tmp = optimize.brentq(eval_inef_ratio,phi,1,args = (phi,e_dev,r_star))\n",
    "                #phi_tmp = optimize.bisect(eval_inef_ratio,phi,1,args = (phi,e_dev,r_star))\n",
    "                weights_lik = eval_weights(phi_tmp.x,phi,e_dev)\n",
    "                phi = phi_tmp.x \n",
    "                #weights_lik = eval_weights(phi_tmp,phi,e_dev)\n",
    "                #phi = phi_tmp\n",
    "            weights_val = eval_weights_avg(weights_lik)\n",
    "            #print(weights_val.min())\n",
    "            #multisample = multinomial_robust(no_simu, weights_val.flatten())\n",
    "            multisample = np.random.multinomial(no_simu, weights_val.flatten(), size=1).flatten() #resampling based on weights\n",
    "            X_next = np.repeat(X_next,multisample,axis = 0) #Creating a new sample based on the weights\n",
    "            Eta_mutate = X_next - X_ft\n",
    "            for mt in range(markov_time):\n",
    "                #print('runnnn')\n",
    "                Eta_mutate_tmp = Eta_mutate + c_var * mutate_shock[t,:,:,iterate,mt]\n",
    "                X_next_mt_sample = X_ft + Eta_mutate_tmp          #Propagate the paricle forward\n",
    "                y_dev_mt_sample = x_obs[t,:] -X_next_mt_sample @ H.T - const_obs\n",
    "                e_dev_mt_sample = 0.5 * np.diag(( y_dev_mt_sample) @ ( inv_Var_y) @ (y_dev_mt_sample).T)\n",
    "                p_yx_tmp =  - phi* e_dev_mt_sample\n",
    "                X_next_mt_past = X_ft + Eta_mutate             #Propagate the paricle forward\n",
    "                y_dev_mt_past = x_obs[t,:] -X_next_mt_past @ H.T - const_obs\n",
    "                e_dev_mt_past = 0.5 * np.diag(( y_dev_mt_past) @ ( inv_Var_y) @ (y_dev_mt_past).T)\n",
    "                p_yx_past =  - phi* e_dev_mt_past\n",
    "                pr_ratio = -0.5 * np.sum(Eta_mutate_tmp**2 -Eta_mutate**2,1)\n",
    "                acceptance_rate = np.exp( p_yx_tmp - p_yx_past + pr_ratio)\n",
    "                decision = acceptance_rate > accept_shock[mt,:,t,iterate]\n",
    "                tiled_decision = np.tile(decision,(no_state,1)).T\n",
    "                Eta_mutate = Eta_mutate_tmp * tiled_decision + (1 - tiled_decision) * Eta_mutate\n",
    "                #print(decision.sum()/no_simu)\n",
    "            c_var = c_var * c_var_updater_mh(decision.sum()/no_simu)\n",
    "            X_next = X_ft + Eta_mutate\n",
    "            iterate = iterate +1\n",
    "            lnp = np.log(np.mean(weights_lik))  + lnp\n",
    "            #lnp = np.log(np.sum(weights_val))  + lnp\n",
    "            #print(lnp)\n",
    "        X = X_next.copy()\n",
    "        #print(t)\n",
    "    return lnp- 0.5 * T * no_measurement *  np.log(2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-287.04619689891263"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempered_particle_filter(F,G,H,J,x_obs,Const_obs,3000,r_star = 2,phi_init = 0.002,markov_time = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
